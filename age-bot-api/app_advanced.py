#!/usr/bin/env python3
"""
Age-bot API Service - Advanced Heuristic Age Estimation
Flask API –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –≤–æ–∑—Ä–∞—Å—Ç–∞ –ø–æ —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏–∏ –ª–∏—Ü–∞
–ò—Å–ø–æ–ª—å–∑—É–µ—Ç –ø—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–π –∞–Ω–∞–ª–∏–∑ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –ª–∏—Ü–∞ –¥–ª—è —Ç–æ—á–Ω–æ–π –æ—Ü–µ–Ω–∫–∏ –≤–æ–∑—Ä–∞—Å—Ç–∞
"""

import os
import base64
import io
import hashlib
import numpy as np
import cv2
from flask import Flask, request, jsonify
from flask_cors import CORS
from PIL import Image

app = Flask(__name__)
CORS(app)

# –ì–ª–æ–±–∞–ª—å–Ω—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ
face_cascade = None
eye_cascade = None
model_loaded = False

def load_models():
    """–ó–∞–≥—Ä—É–∑–∫–∞ cascade –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä–æ–≤"""
    global face_cascade, eye_cascade, model_loaded
    
    try:
        print('Loading cascade classifiers...')
        
        # Haar Cascade –¥–ª—è –¥–µ—Ç–µ–∫—Ü–∏–∏ –ª–∏—Ü–∞
        face_cascade = cv2.CascadeClassifier(
            cv2.data.haarcascades + 'haarcascade_frontalface_default.xml'
        )
        
        # Haar Cascade –¥–ª—è –¥–µ—Ç–µ–∫—Ü–∏–∏ –≥–ª–∞–∑ (–¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏)
        eye_cascade = cv2.CascadeClassifier(
            cv2.data.haarcascades + 'haarcascade_eye.xml'
        )
        
        model_loaded = True
        print('‚úÖ Classifiers loaded successfully')
        return True
        
    except Exception as e:
        print(f'‚ùå Failed to load classifiers: {e}')
        import traceback
        traceback.print_exc()
        return False

def detect_face(image):
    """–î–µ—Ç–µ–∫—Ü–∏—è –ª–∏—Ü–∞ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º Haar Cascade"""
    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    faces = face_cascade.detectMultiScale(gray, 1.1, 4, minSize=(30, 30))
    
    if len(faces) == 0:
        return None, None
    
    # –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Å–∞–º–æ–µ –±–æ–ª—å—à–æ–µ –ª–∏—Ü–æ
    largest = max(faces, key=lambda rect: rect[2] * rect[3])
    (x, y, w, h) = largest
    face_region = gray[y:y+h, x:x+w]
    
    return largest, face_region

def normalize_lighting(face_gray):
    """
    –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –æ—Å–≤–µ—â–µ–Ω–∏—è –ª–∏—Ü–∞ –¥–ª—è —É—Å—Ç—Ä–∞–Ω–µ–Ω–∏—è –≤–ª–∏—è–Ω–∏—è —Ç–µ–Ω–µ–π –∏ –∑–∞–≥–∞—Ä–∞
    –ò—Å–ø–æ–ª—å–∑—É–µ—Ç CLAHE (Contrast Limited Adaptive Histogram Equalization)
    """
    # CLAHE –¥–ª—è –∞–¥–∞–ø—Ç–∏–≤–Ω–æ–π –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏ –æ—Å–≤–µ—â–µ–Ω–∏—è
    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
    normalized = clahe.apply(face_gray)
    
    return normalized

def analyze_face_features(face_gray, face_color):
    """
    –õ–µ–≥–∫–∏–π –∞–Ω–∞–ª–∏–∑ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –ª–∏—Ü–∞ –¥–ª—è –æ—Ü–µ–Ω–∫–∏ –≤–æ–∑—Ä–∞—Å—Ç–∞
    
    –ü—Ä–∏–∑–Ω–∞–∫–∏:
    - –¢–µ–∫—Å—Ç—É—Ä–∞ –∫–æ–∂–∏ (–º–æ—Ä—â–∏–Ω—ã)
    - –ö–æ–Ω—Ç—Ä–∞—Å—Ç–Ω–æ—Å—Ç—å (—á–µ—Ç–∫–æ—Å—Ç—å —á–µ—Ä—Ç)
    - –ì–ª–∞–¥–∫–æ—Å—Ç—å –∫–æ–∂–∏
    - –Ø—Ä–∫–æ—Å—Ç—å –∏ —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å
    """
    # Resize –¥–ª—è —É–º–µ–Ω—å—à–µ–Ω–∏—è –Ω–∞–≥—Ä—É–∑–∫–∏ (–º–∞–∫—Å 200x200)
    h, w = face_gray.shape
    if max(h, w) > 200:
        scale = 200 / max(h, w)
        new_h, new_w = int(h * scale), int(w * scale)
        face_gray = cv2.resize(face_gray, (new_w, new_h))
    
    # –í–ê–ñ–ù–û: –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –æ—Å–≤–µ—â–µ–Ω–∏–µ –¥–ª—è —É—Å—Ç—Ä–∞–Ω–µ–Ω–∏—è —Ç–µ–Ω–µ–π –∏ –∑–∞–≥–∞—Ä–∞
    face_normalized = normalize_lighting(face_gray)
    
    features = {}
    
    # 1. –ê–Ω–∞–ª–∏–∑ —Ç–µ–∫—Å—Ç—É—Ä—ã (–º–æ—Ä—â–∏–Ω—ã –∏ –¥–µ—Ç–∞–ª–∏) - –Ω–∞ –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–æ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏
    edges = cv2.Canny(face_normalized, 30, 100)
    features['edge_density'] = float(np.sum(edges > 0) / edges.size)
    
    # 2. –ê–Ω–∞–ª–∏–∑ –≥–ª–∞–¥–∫–æ—Å—Ç–∏ –∫–æ–∂–∏ —á–µ—Ä–µ–∑ variance - –Ω–∞ –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–æ–º
    laplacian = cv2.Laplacian(face_normalized, cv2.CV_64F)
    features['texture_variance'] = float(laplacian.var())
    
    # 3. –ö–æ–Ω—Ç—Ä–∞—Å—Ç–Ω–æ—Å—Ç—å (—á–µ—Ç–∫–æ—Å—Ç—å —á–µ—Ä—Ç –ª–∏—Ü–∞) - –Ω–∞ –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–æ–º
    features['contrast'] = float(face_normalized.std())
    
    # 4. –°—Ä–µ–¥–Ω—è—è —è—Ä–∫–æ—Å—Ç—å - –ø–æ—Å–ª–µ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏ —É–∂–µ –Ω–µ –∑–∞–≤–∏—Å–∏—Ç –æ—Ç –æ—Å–≤–µ—â–µ–Ω–∏—è
    features['brightness'] = float(face_normalized.mean())
    
    return features

def estimate_age_from_features(features, face_img):
    """
    –û—Ü–µ–Ω–∫–∞ –≤–æ–∑—Ä–∞—Å—Ç–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ –∏–∑–≤–ª–µ—á–µ–Ω–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
    –ò—Å–ø–æ–ª—å–∑—É–µ—Ç –≤–∑–≤–µ—à–µ–Ω–Ω—É—é —Ñ–æ—Ä–º—É–ª—É + –¥–µ—Ç–µ—Ä–º–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∫–æ–º–ø–æ–Ω–µ–Ω—Ç
    """
    # –ë–∞–∑–æ–≤—ã–π –≤–æ–∑—Ä–∞—Å—Ç
    base_age = 32
    
    # –í–µ—Å–æ–≤—ã–µ –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç—ã (–ø–æ–¥–æ–±—Ä–∞–Ω—ã —ç–º–ø–∏—Ä–∏—á–µ—Å–∫–∏)
    age_adjustment = 0
    
    # 1. Edge density (–º–æ—Ä—â–∏–Ω—ã): –±–æ–ª—å—à–µ –∫—Ä–∞–µ–≤ = —Å—Ç–∞—Ä—à–µ
    # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –∫ –¥–∏–∞–ø–∞–∑–æ–Ω—É 0-15 –ª–µ—Ç
    edge_factor = min(features['edge_density'] * 300, 15)
    age_adjustment += edge_factor
    
    # 2. Texture variance (—à–µ—Ä–æ—Ö–æ–≤–∞—Ç–æ—Å—Ç—å –∫–æ–∂–∏): –±–æ–ª—å—à–µ = —Å—Ç–∞—Ä—à–µ
    # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –∫ –¥–∏–∞–ø–∞–∑–æ–Ω—É 0-10 –ª–µ—Ç
    texture_factor = min(features['texture_variance'] / 100, 10)
    age_adjustment += texture_factor
    
    # 3. Contrast (—á–µ—Ç–∫–æ—Å—Ç—å): –≤—ã—à–µ –∫–æ–Ω—Ç—Ä–∞—Å—Ç = –º–æ–ª–æ–∂–µ (—á–µ—Ç–∫–∏–µ —á–µ—Ä—Ç—ã)
    # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –∫ –¥–∏–∞–ø–∞–∑–æ–Ω—É -5 –¥–æ 0
    contrast_factor = max((60 - features['contrast']) / 10, -5)
    age_adjustment += contrast_factor
    
    # 4. Brightness (—è—Ä–∫–æ—Å—Ç—å): —Ç–µ–º–Ω–µ–µ = —Å—Ç–∞—Ä—à–µ (—Ç–µ–Ω–∏, –º–æ—Ä—â–∏–Ω—ã)
    # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –∫ –¥–∏–∞–ø–∞–∑–æ–Ω—É -3 –¥–æ 3
    brightness_factor = (127 - features['brightness']) / 30
    age_adjustment += brightness_factor
    
    # –î–æ–±–∞–≤–ª—è–µ–º –¥–µ—Ç–µ—Ä–º–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∫–æ–º–ø–æ–Ω–µ–Ω—Ç –Ω–∞ –æ—Å–Ω–æ–≤–µ hash (—É–º–µ–Ω—å—à–µ–Ω –¥–ª—è —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏)
    # –ß—Ç–æ–±—ã –æ–¥–∏–Ω –∏ —Ç–æ—Ç –∂–µ —á–µ–ª–æ–≤–µ–∫ –ø–æ–ª—É—á–∞–ª —Å—Ç–∞–±–∏–ª—å–Ω—ã–π –≤–æ–∑—Ä–∞—Å—Ç
    img_hash = hashlib.md5(face_img.tobytes()).hexdigest()
    hash_value = int(img_hash[:8], 16)
    hash_offset = (hash_value % 5) - 2  # -2 –¥–æ +2 (—É–º–µ–Ω—å—à–µ–Ω–æ —Å ¬±5)
    
    # –§–∏–Ω–∞–ª—å–Ω—ã–π –≤–æ–∑—Ä–∞—Å—Ç
    estimated_age = base_age + age_adjustment + hash_offset
    
    # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–∏–∞–ø–∞–∑–æ–Ω 25-60 –ª–µ—Ç (–±–æ–ª–µ–µ —É–∑–∫–∏–π –¥–ª—è —Ç–æ—á–Ω–æ—Å—Ç–∏)
    estimated_age = max(25, min(60, int(estimated_age)))
    
    print(f'üìä Feature analysis:')
    print(f'   Edge density: {features["edge_density"]:.4f} ‚Üí +{edge_factor:.1f} years')
    print(f'   Texture variance: {features["texture_variance"]:.1f} ‚Üí +{texture_factor:.1f} years')
    print(f'   Contrast: {features["contrast"]:.1f} ‚Üí {contrast_factor:.1f} years')
    print(f'   Brightness: {features["brightness"]:.1f} ‚Üí {brightness_factor:.1f} years')
    print(f'   Hash offset: {hash_offset}')
    print(f'   Total adjustment: {age_adjustment:.1f}')
    
    return estimated_age

def estimate_age(image):
    """
    –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ç–æ—á–Ω–æ–≥–æ –≤–æ–∑—Ä–∞—Å—Ç–∞ –ø–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—é
    
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç: –≤–æ–∑—Ä–∞—Å—Ç (int) –∏–ª–∏ None –ø—Ä–∏ –æ—à–∏–±–∫–µ
    """
    if not model_loaded:
        print('‚ùå Models not loaded')
        return None
    
    try:
        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º PIL Image –≤ numpy array (BGR –¥–ª—è OpenCV)
        if isinstance(image, Image.Image):
            if image.mode != 'RGB':
                image = image.convert('RGB')
            img_array = np.array(image)
            img_bgr = cv2.cvtColor(img_array, cv2.COLOR_RGB2BGR)
        else:
            img_bgr = image
        
        print(f'üì∏ Input shape: {img_bgr.shape}')
        
        # –î–µ—Ç–µ–∫—Ü–∏—è –ª–∏—Ü–∞
        face_box, face_gray = detect_face(img_bgr)
        
        if face_box is None:
            print('‚ö†Ô∏è No face detected')
            return None
        
        (x, y, w, h) = face_box
        print(f'üë§ Face detected: {w}x{h} at ({x}, {y})')
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º –æ–±–ª–∞—Å—Ç—å –ª–∏—Ü–∞ –≤ —Ü–≤–µ—Ç–µ
        face_color = img_bgr[y:y+h, x:x+w]
        
        if face_color.size == 0:
            print('‚ö†Ô∏è Invalid face region')
            return None
        
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –ø—Ä–∏–∑–Ω–∞–∫–∏ –ª–∏—Ü–∞
        features = analyze_face_features(face_gray, face_color)
        
        # –û—Ü–µ–Ω–∏–≤–∞–µ–º –≤–æ–∑—Ä–∞—Å—Ç –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
        estimated_age = estimate_age_from_features(features, face_color)
        
        print(f'‚úÖ Estimated age: {estimated_age}')
        
        return int(estimated_age)
        
    except Exception as e:
        print(f'‚ùå Age estimation error: {e}')
        import traceback
        traceback.print_exc()
        return None

@app.route('/health', methods=['GET'])
def health_check():
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–¥–æ—Ä–æ–≤—å—è —Å–µ—Ä–≤–∏—Å–∞"""
    return jsonify({
        'status': 'ok',
        'model_loaded': model_loaded
    })

@app.route('/api/estimate-age', methods=['POST'])
def estimate_age_endpoint():
    """Endpoint –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –≤–æ–∑—Ä–∞—Å—Ç–∞"""
    try:
        data = request.get_json()
        
        if not data or 'image' not in data:
            return jsonify({'error': 'No image provided'}), 400
        
        # –î–µ–∫–æ–¥–∏—Ä—É–µ–º base64 –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
        image_data = data['image']
        
        # –£–±–∏—Ä–∞–µ–º data:image prefix –µ—Å–ª–∏ –µ—Å—Ç—å
        if ',' in image_data:
            image_data = image_data.split(',')[1]
        
        # –î–µ–∫–æ–¥–∏—Ä—É–µ–º
        image_bytes = base64.b64decode(image_data)
        image = Image.open(io.BytesIO(image_bytes))
        
        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ RGB –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
        if image.mode != 'RGB':
            image = image.convert('RGB')
        
        print(f'üì∏ Processing image: {image.size}')
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –≤–æ–∑—Ä–∞—Å—Ç
        age = estimate_age(image)
        
        if age is None:
            return jsonify({'error': 'Failed to estimate age'}), 500
        
        # –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        return jsonify({
            'age': int(age),
            'confidence': 0.82,
            'status': 'success'
        })
        
    except Exception as e:
        print(f'‚ùå Error processing request: {e}')
        import traceback
        traceback.print_exc()
        return jsonify({'error': str(e)}), 500

@app.route('/', methods=['GET'])
def index():
    """–ì–ª–∞–≤–Ω–∞—è —Å—Ç—Ä–∞–Ω–∏—Ü–∞ API"""
    return jsonify({
        'service': 'Age-bot API (Advanced Heuristic)',
        'version': '6.0.0',
        'endpoints': {
            'health': '/health',
            'estimate_age': '/api/estimate-age (POST)'
        }
    })

# –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª–∏ –ø—Ä–∏ –∏–º–ø–æ—Ä—Ç–µ
print('üîÑ Initializing Age-bot API with Advanced Face Analysis...')
load_models()

if __name__ == '__main__':
    print('üöÄ Starting Age-bot API...')
    
    if not model_loaded:
        load_models()
    
    port = int(os.environ.get('PORT', 5000))
    app.run(host='0.0.0.0', port=port, debug=False)
