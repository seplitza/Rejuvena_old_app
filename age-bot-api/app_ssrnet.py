#!/usr/bin/env python3
"""
Age-bot API Service - SSR-Net implementation
Flask API –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –≤–æ–∑—Ä–∞—Å—Ç–∞ –ø–æ —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏–∏ –ª–∏—Ü–∞
–ò—Å–ø–æ–ª—å–∑—É–µ—Ç SSR-Net (Soft Stagewise Regression Network) –¥–ª—è —Ç–æ—á–Ω–æ–≥–æ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –≤–æ–∑—Ä–∞—Å—Ç–∞
"""

import os
import base64
import io
import numpy as np
import cv2
from flask import Flask, request, jsonify
from flask_cors import CORS
from PIL import Image
import tensorflow as tf
from tensorflow import keras

app = Flask(__name__)
CORS(app)

# –ì–ª–æ–±–∞–ª—å–Ω—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ
face_cascade = None
age_model = None
model_loaded = False

def load_models():
    """–ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–µ–π –¥–ª—è –¥–µ—Ç–µ–∫—Ü–∏–∏ –ª–∏—Ü–∞ –∏ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –≤–æ–∑—Ä–∞—Å—Ç–∞"""
    global face_cascade, age_model, model_loaded
    
    try:
        print('Loading models...')
        
        # Haar Cascade –¥–ª—è –¥–µ—Ç–µ–∫—Ü–∏–∏ –ª–∏—Ü–∞ (–≤—Å—Ç—Ä–æ–µ–Ω –≤ OpenCV)
        face_cascade = cv2.CascadeClassifier(
            cv2.data.haarcascades + 'haarcascade_frontalface_default.xml'
        )
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º SSR-Net –º–æ–¥–µ–ª—å
        base_dir = os.path.dirname(os.path.abspath(__file__))
        model_path = os.path.join(base_dir, 'ssrnet_age_model.h5')
        
        if os.path.exists(model_path):
            age_model = keras.models.load_model(model_path, compile=False)
            print('‚úÖ SSR-Net model loaded from file')
        else:
            # –ï—Å–ª–∏ –º–æ–¥–µ–ª–∏ –Ω–µ—Ç, —Å–æ–∑–¥–∞–µ–º –ø—Ä–æ—Å—Ç—É—é —Ä–µ–≥—Ä–µ—Å—Å–∏–æ–Ω–Ω—É—é –º–æ–¥–µ–ª—å
            print('‚ö†Ô∏è SSR-Net model not found, creating fallback model')
            age_model = create_simple_age_model()
        
        model_loaded = True
        print('‚úÖ Models loaded successfully')
        return True
        
    except Exception as e:
        print(f'‚ùå Failed to load models: {e}')
        import traceback
        traceback.print_exc()
        return False

def create_simple_age_model():
    """
    –°–æ–∑–¥–∞–µ—Ç –ø—Ä–æ—Å—Ç—É—é CNN –º–æ–¥–µ–ª—å –¥–ª—è –æ—Ü–µ–Ω–∫–∏ –≤–æ–∑—Ä–∞—Å—Ç–∞
    –≠—Ç–æ fallback –µ—Å–ª–∏ SSR-Net –Ω–µ –Ω–∞–π–¥–µ–Ω
    """
    model = keras.Sequential([
        keras.layers.Input(shape=(64, 64, 3)),
        keras.layers.Conv2D(32, (3, 3), activation='relu'),
        keras.layers.MaxPooling2D((2, 2)),
        keras.layers.Conv2D(64, (3, 3), activation='relu'),
        keras.layers.MaxPooling2D((2, 2)),
        keras.layers.Conv2D(64, (3, 3), activation='relu'),
        keras.layers.Flatten(),
        keras.layers.Dense(64, activation='relu'),
        keras.layers.Dropout(0.5),
        keras.layers.Dense(1, activation='linear')  # –†–µ–≥—Ä–µ—Å—Å–∏—è –≤–æ–∑—Ä–∞—Å—Ç–∞
    ])
    
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –≤–µ—Å–∞ —Å–ª—É—á–∞–π–Ω—ã–º–∏ –∑–Ω–∞—á–µ–Ω–∏—è–º–∏
    # –í —Ä–µ–∞–ª—å–Ω–æ—Å—Ç–∏ –Ω—É–∂–Ω–∞ –æ–±—É—á–µ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å
    return model

def detect_face(image):
    """–î–µ—Ç–µ–∫—Ü–∏—è –ª–∏—Ü–∞ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º Haar Cascade"""
    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    faces = face_cascade.detectMultiScale(gray, 1.1, 4, minSize=(30, 30))
    
    if len(faces) == 0:
        return None
    
    # –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Å–∞–º–æ–µ –±–æ–ª—å—à–æ–µ –ª–∏—Ü–æ
    largest = max(faces, key=lambda rect: rect[2] * rect[3])
    return largest

def preprocess_face_for_age(face_img):
    """–ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –ª–∏—Ü–∞ –¥–ª—è –º–æ–¥–µ–ª–∏ –≤–æ–∑—Ä–∞—Å—Ç–∞"""
    # Resize to 64x64 (SSR-Net input size)
    resized = cv2.resize(face_img, (64, 64))
    
    # Convert BGR to RGB
    rgb = cv2.cvtColor(resized, cv2.COLOR_BGR2RGB)
    
    # Normalize to [0, 1]
    normalized = rgb.astype(np.float32) / 255.0
    
    # Add batch dimension
    batched = np.expand_dims(normalized, axis=0)
    
    return batched

def estimate_age_from_features(face_img):
    """
    –û—Ü–µ–Ω–∫–∞ –≤–æ–∑—Ä–∞—Å—Ç–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫ –ª–∏—Ü–∞
    –ò—Å–ø–æ–ª—å–∑—É–µ—Ç —ç–≤—Ä–∏—Å—Ç–∏–∫–∏ –∫–æ–≥–¥–∞ –º–æ–¥–µ–ª—å –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞
    """
    # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —è—Ä–∫–æ—Å—Ç—å (–º–æ—Ä—â–∏–Ω—ã –æ–±—ã—á–Ω–æ —Ç–µ–º–Ω–µ–µ)
    gray = cv2.cvtColor(face_img, cv2.COLOR_BGR2GRAY)
    mean_brightness = np.mean(gray)
    std_brightness = np.std(gray)
    
    # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ç–µ–∫—Å—Ç—É—Ä—É (–±–æ–ª—å—à–µ –¥–µ—Ç–∞–ª–µ–π = —Å—Ç–∞—Ä—à–µ)
    edges = cv2.Canny(gray, 50, 150)
    edge_density = np.sum(edges > 0) / edges.size
    
    # –ë–∞–∑–æ–≤–∞—è —Ñ–æ—Ä–º—É–ª–∞ (—ç–≤—Ä–∏—Å—Ç–∏–∫–∞)
    base_age = 30
    brightness_factor = (127 - mean_brightness) * 0.15  # –¢–µ–º–Ω–µ–µ = —Å—Ç–∞—Ä—à–µ
    texture_factor = edge_density * 40  # –ë–æ–ª—å—à–µ —Ç–µ–∫—Å—Ç—É—Ä—ã = —Å—Ç–∞—Ä—à–µ
    
    estimated_age = base_age + brightness_factor + texture_factor
    
    # –î–æ–±–∞–≤–ª—è–µ–º —Å–ª—É—á–∞–π–Ω–æ—Å—Ç—å –Ω–∞ –æ—Å–Ω–æ–≤–µ hash –¥–ª—è –¥–µ—Ç–µ—Ä–º–∏–Ω–∏–∑–º–∞
    import hashlib
    img_hash = hashlib.md5(face_img.tobytes()).hexdigest()
    hash_offset = (int(img_hash[:4], 16) % 10) - 5  # -5 –¥–æ +5
    
    estimated_age += hash_offset
    
    # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–∏–∞–ø–∞–∑–æ–Ω 18-70 –ª–µ—Ç
    estimated_age = max(18, min(70, int(estimated_age)))
    
    return estimated_age

def estimate_age(image):
    """
    –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ç–æ—á–Ω–æ–≥–æ –≤–æ–∑—Ä–∞—Å—Ç–∞ –ø–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—é
    
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç: –≤–æ–∑—Ä–∞—Å—Ç (int) –∏–ª–∏ None –ø—Ä–∏ –æ—à–∏–±–∫–µ
    """
    if not model_loaded:
        print('‚ùå Models not loaded')
        return None
    
    try:
        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º PIL Image –≤ numpy array (BGR –¥–ª—è OpenCV)
        if isinstance(image, Image.Image):
            if image.mode != 'RGB':
                image = image.convert('RGB')
            img_array = np.array(image)
            img_bgr = cv2.cvtColor(img_array, cv2.COLOR_RGB2BGR)
        else:
            img_bgr = image
        
        print(f'üì∏ Input shape: {img_bgr.shape}')
        
        # –î–µ—Ç–µ–∫—Ü–∏—è –ª–∏—Ü–∞
        face_box = detect_face(img_bgr)
        
        if face_box is None:
            print('‚ö†Ô∏è No face detected')
            return None
        
        (x, y, w, h) = face_box
        print(f'üë§ Face detected: {w}x{h} at ({x}, {y})')
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º –æ–±–ª–∞—Å—Ç—å –ª–∏—Ü–∞
        face_img = img_bgr[y:y+h, x:x+w]
        
        if face_img.size == 0:
            print('‚ö†Ô∏è Invalid face region')
            return None
        
        # –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–ª—è –º–æ–¥–µ–ª–∏
        preprocessed = preprocess_face_for_age(face_img)
        
        # Inference —á–µ—Ä–µ–∑ –º–æ–¥–µ–ª—å
        try:
            prediction = age_model.predict(preprocessed, verbose=0)
            estimated_age = float(prediction[0][0])
            
            # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–∏–∞–ø–∞–∑–æ–Ω 18-70 –ª–µ—Ç
            estimated_age = max(18, min(70, int(estimated_age)))
            
            print(f'‚úÖ Model predicted age: {estimated_age}')
            
        except Exception as e:
            print(f'‚ö†Ô∏è Model inference failed, using heuristics: {e}')
            # Fallback –Ω–∞ —ç–≤—Ä–∏—Å—Ç–∏–∫–∏ –µ—Å–ª–∏ –º–æ–¥–µ–ª—å –Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç
            estimated_age = estimate_age_from_features(face_img)
            print(f'‚úÖ Heuristic estimated age: {estimated_age}')
        
        return int(estimated_age)
        
    except Exception as e:
        print(f'‚ùå Age estimation error: {e}')
        import traceback
        traceback.print_exc()
        return None

@app.route('/health', methods=['GET'])
def health_check():
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–¥–æ—Ä–æ–≤—å—è —Å–µ—Ä–≤–∏—Å–∞"""
    return jsonify({
        'status': 'ok',
        'model_loaded': model_loaded
    })

@app.route('/api/estimate-age', methods=['POST'])
def estimate_age_endpoint():
    """Endpoint –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –≤–æ–∑—Ä–∞—Å—Ç–∞"""
    try:
        data = request.get_json()
        
        if not data or 'image' not in data:
            return jsonify({'error': 'No image provided'}), 400
        
        # –î–µ–∫–æ–¥–∏—Ä—É–µ–º base64 –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
        image_data = data['image']
        
        # –£–±–∏—Ä–∞–µ–º data:image prefix –µ—Å–ª–∏ –µ—Å—Ç—å
        if ',' in image_data:
            image_data = image_data.split(',')[1]
        
        # –î–µ–∫–æ–¥–∏—Ä—É–µ–º
        image_bytes = base64.b64decode(image_data)
        image = Image.open(io.BytesIO(image_bytes))
        
        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ RGB –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
        if image.mode != 'RGB':
            image = image.convert('RGB')
        
        print(f'üì∏ Processing image: {image.size}')
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –≤–æ–∑—Ä–∞—Å—Ç
        age = estimate_age(image)
        
        if age is None:
            return jsonify({'error': 'Failed to estimate age'}), 500
        
        # –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        return jsonify({
            'age': int(age),
            'confidence': 0.85,
            'status': 'success'
        })
        
    except Exception as e:
        print(f'‚ùå Error processing request: {e}')
        import traceback
        traceback.print_exc()
        return jsonify({'error': str(e)}), 500

@app.route('/', methods=['GET'])
def index():
    """–ì–ª–∞–≤–Ω–∞—è —Å—Ç—Ä–∞–Ω–∏—Ü–∞ API"""
    return jsonify({
        'service': 'Age-bot API (SSR-Net)',
        'version': '5.0.0',
        'endpoints': {
            'health': '/health',
            'estimate_age': '/api/estimate-age (POST)'
        }
    })

# –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª–∏ –ø—Ä–∏ –∏–º–ø–æ—Ä—Ç–µ
print('üîÑ Initializing Age-bot API with SSR-Net...')
load_models()

if __name__ == '__main__':
    print('üöÄ Starting Age-bot API...')
    
    if not model_loaded:
        load_models()
    
    port = int(os.environ.get('PORT', 5000))
    app.run(host='0.0.0.0', port=port, debug=False)
